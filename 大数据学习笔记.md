# BIG DATA 课程笔记

## CH1 导论

大数据的四大特征

​	**大量化、快速化、多样化、价值化**

大数据分析的三个特征

​	**全样而非抽样、效率而非精确、相关而非因果**

大数据处理模型：

​	批处理：以“静止数据”为出发点，处理逻辑进来，算完后价值出去

​	流数据：不动的是逻辑，“动态数据”进来，计算完后价值留下，原始数据加入“静止数		据”，或索性丢弃

其中批处理包括MapReduce模型

大数据技术和工具

- NoSQL，not only sql，模式自由、简易备份、简单API、不支持ACID但是支持BASE、支持海量数据
  - 做了查询优化
    - 利用MapReduce时并行查询、每个MapTask处理一部分
  - 采用索引技术优化多指查询，多维索引
- 流处理模式：Storm
- 工具：Hadoop、Spark

---

## CH2 Hadoop

### 概念

1. MapReduce采用了分布式文件系统即HDFS，也就是Hadoop 分布式文件系统，MapReduce是用来整合DFS的数据的

2. 存储冗余数据保证安全性

3. 对比关系型数据库RDBMS，RDBMS适合查询更新、MapReduce适合批处理。RDBMS 适合持续更新的数据集，MapReduce适合一次写入多次读取。RDBNMS只能处理结构化数据，MapReduce能够处理半结构化或者非结构化。

   ![image-20220405200729138](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405200729138.png)

### 体系结构



![image-20220405201056878](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405201056878.png)

- 最底部是Hadoop分布式文件系统（HDFS），它存储Hadoop集群中所有存储节点上的文件

- HDFS的上一层是MapReduce引擎
- HBase位于结构化存储层，是一个分布式的列存储数据库
- Zookeeper是一个分布式的、高可用性的协调服务，提供分布式锁之类的基本服务
- Hive是一个建立在Hadoop 基础之上的数据仓库，用于管理存储于HDFS或Hbase中的结构化/半结构化数据
- Pig提供一种数据流语言，程序员可以将复杂的数据分析任务实现为Pig操作上的数据流脚本，这些脚本可自动转换为MapReduce任务链，在Hadoop上执行，从而简化程序员的数据分析工作难度
- Sqoop是SQL-to-Hadoop的缩写，为在RDBMS与Hadoop平台（HDFS, Hbase, Hive）间进行快速批量数据交换
- Avro是个数据序列化的系统，用于将数据对象转换成便于数据存储和网络传输的格式
- 一个HDFS集群是由一个NameNode和若干个DataNode组成
- NameNode作为主服务器，**管理文件系统的命名空间和客户端对文件的访问操作**；集群中的**DataNode管理存储的数据**
- HDFS支持用户以文件的形式存储数据，文件被分成若干个数据块，而且这若干个数据块存放在一组DataNode上
- 具体到程序层面：MapReduce框架是由一个单独运行在主节点上的JobTracker 和运行在每个集群从节点上的TaskTracker共同组成的
  - 主节点负责调度构成一个作业的所有任务，这些任务分布在不同的从节点上；主节点监控它们的执行情况，并且重新执行之前失败的任务。从节点仅负责由主节点指派的任务
  - 当一个Job 被提交时，JobTracker接收到提交作业和配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行
- TaskTracker和DataNode需配对的设置在同一个物理的从节点服务器上；JobTracker和NameNode可以设置在同一个物理主控节点服务器上，也可以分开设置

### Hadoop与分布式开发

![image-20220405202959992](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405202959992.png)

![image-20220405204705230](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405204705230.png)

**编程原理**

- 利用一个输入的key/value 对集合,来产生一个输出的key/value 对集合。这个过程基于Map 和Reduce这两个用户自定义函数实现
- 用户自定义的map函数接收一个输入的key/value 对，然后产生一个中间key/value 对的集合
- MapReduce（shuffle）把所有具有相同key值的value集合在一起，然后传递给reduce 函数
- 用户自定义的reduce 函数接收key和相关的value集合，合并这些value 值，形成一个较小的value 集合。一般来说，每次reduce 函数调用只产生0 或1 个输出的value值
- 通常通过一个迭代器把中间的value 值提供给reduce 函数，这样就可以处理无法全部放入内存中的大量的value 值集合

**基于Map和Reduce的并行计算模型**

![image-20220405203254179](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405203254179.png)

其中

- Barrier是同步障

---

## CH3 存储——HDFS

### 概念

- HDFS的块是抽象的概念，默认块为64MB，比一般文件系统中所说的块（若干KB）要大得多
  - 好处：文件大、便于操作、复制容错
- 两类节点：NameNode和DataNode
  - NameNode：集群里面的主节点，负责管理整个HDFS系统的命名空间和元数据，也是客户端访问HDFS系统的入口
  - 三种**元数据metadata如下**
    - 命名空间：即目录结构、命名空间维护操作包括文件和目录的创建删除重命名
    - 数据块和文件名的映射表：客户点需要访问NameNode才知道一个文件所有的数据块保存在那些DataNode上
    - 数据块副本的位置信息，默认三个副本，可以指定部分银子Replication Factor
    - 承担Master任务
  - DataNode：负责数据读取和存储
    - 写入时：目录节点分配数据块，直接写入对应的DataNode
    - 读取：客户点从NameNode获得映射关系后，直接到DataNode读
    - DataNode根据NameNode的命令创建、删除数据块，副本复制

### HDFS 体系结构

![image-20220405205441702](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405205441702.png)

- HDFS是经典的主从结构
- HDFS的基本文件的访问过程
  - 通过HDFS客户端，奖文件名发送到NameNode
  - 接收后，在HDFS目录中检索文件名对应的数据库，找到对应的DataNode，然后送回客户端
  - 接收后，与DataNode并行进行数据传输，提交操作日志到NameNode
- HDFS不允许使用链接
- 为了保证可靠性，底层使用TCP来传输。
  - 应用向NameNode主动发出TCP链接，交互的协议成为Client协议
  - NameNode与DataNode传输的协议成为DataNode协议
  - 用户与Datanode的协议是通过远程过程调用RPC、并由NameNode相应来实现
  - 如下图

![image-20220405213033545](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213033545.png)

![image-20220405210648449](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405210648449.png)

这个图可以看出什么信息呢？

- Client会从Datanodes读
- Client写的时候 会写副本吗？
- Rack是机柜，Replication是复制、
- Namenode会对Datanodes进行快操作

### HDFS可靠性设计

- 除了文件的最后一块以外其它所有的数据块都是固定大小的，为了数据容错性，每一个数据块都会被冗余存储起来

- 目录节点根据数据块的副本状况来作出处理决策，数据节点会定期发送一个**心跳信号（Heartbeat）**和数据块列表给目录节点，心跳信号使目录节点知道该数据节点还是有效的，而数据块列表包括了该数据节点上面的所有数据块编号

- 数据节点出错的处理

  - 每个数据节点会定时发送一个心跳信息给目录节点，表明自己仍然存活

  - 网络异常可能会导致一部分数据节点无法和目录节点通讯，这时候目录节点收不到心跳信息，就认为该数据节点已死机

    然后：从有效数据节点列表中清除它，而该数据节点上面的所有数据块也会被标记为不可读。目录节点会定期检查副本数，进行复制。

- 数据异常

  - 客户端需实现对数据块的校验，保证数据一致性
  - 在创建文件的时候，HDFS会为文件生成一个校验和（CheckSum），校验和文件与文件本身保存在同一个空间中。数据传输时，将数据与校验和一起传输，客户端对每个读取的数据块进行校验
  - 如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且报告给目录节点这个文件块有错误，目录节点会重新复制这个块

- 目录节点出错

  - HDFS刚启动时，目录节点进入安全模式（safe mode），**此时不做任何文件修改操作**；目录节点和各个数据节点通信，获得数据块信息，并对数据块信息进行检查；认为安全的块比例超过阈值，才退出安全模式

  - 辅助目录节点，用来备份目录节点的元数据，当目录节点失效时，从辅助目录节点恢复出目录节点的元数据

  - 文件镜像数据**FsImage**和编辑日志数据**Editlog**是目录节点元数据中最重要的部分，前者相当于HDFS的**检查点**，后者记录对HDFS的**最新修改信息**

  - 恢复：目录节点启动时，读取FsImage的内容到内存，并将其与Editlog中的所有修改信息合并生成最新的FsImage；目录节点运行中，所有关于HDFS的修改信息，都将写入Editlog

    - FsImage和Editlog时最核心的数据结构
    - 所以存在多个备份文件，在辅助目录节点上再进行备份，增加负担提高可靠性。维护同步

    

### HDFS存储原理

- 以机柜为基础
- 副本因子为3：HDFS将两份放在同一个rack id中，另一个放在不同的rankid的机器上
- 实战中Namenode
  - ![image-20220405213805409](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213805409.png)
  - ![image-20220405213854377](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213854377.png)
  - ![image-20220405213941210](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213941210.png)
- DataNode
  - ![image-20220405214008805](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214008805.png)
  - ![image-20220405214230211](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214230211.png)
  - 

- **数据读取时**
  - 如果有块数据和客户端的机柜id一样，就优先选择该数据节点，客户端直接和数据节点建立连接，读取数据
  - 如果没有，可以随机选取一个数据节点

![image-20220405212824697](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405212824697.png)

![image-20220405212932527](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405212932527.png)

- **数据复制**
  - **流水线复制策略**
  - 当在HDFS上写文件：
    - 先写在本地
    - 对文件分块，64MB
    - 每块数据对HDFS目录节点发起写入请求
    - NameNode选一个DataNode列表，返回给客户端
    - 客户端把数据写入第一台DataNode，列表传给DataNode
    - 当数据节点接收到4KB数据时，写入本地，并且发起到下一台Datanode的连接，传4K，流水线
    - 当文件写完时，数据复制也同时完成？
- **数据写入**
  - ![image-20220405214436163](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214436163.png)
  - ![image-20220405214544884](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214544884.png)

---

### HDFS文件系统操作命令



#### 启动

```shell
start-dfs.sh
# 会启动namenode，然后根据conf/slaves记录诸葛启动Datanode
# 根据 conf/masters中记录的SecondaryNameNode地址 启动SNameNode
stop-dfs.sh
```

#### 文件操作

```shell
# 数值指定的文件到stdout
hadoop dfs-cat URI [URI..] 
```

- chgrp : hadoop dfs -chgrp [-R] GROUP URI [URI ...]
  - 改变文件所属的用户组，-R对目录结构起作用
- chmod: hadoop dfs -chmod [-R] 
  - 改变文件权限
- chown 改变文件所属用户
- copyFromLocal
  - hadoop dfs -copyFromLocal \<localsrc\> URI
  - put命令
- copyToLocal
  - hadoop dfs -copyToLocal \<-ignorecrc\> [-crc] URI \<localdst\>
  - get 命令
- count
  - hadoop dfs -count [-q] \<paths\>
  - 统计匹配对应路径下的目录数、文件数、字节数
- cp
  - 对dfs的文件进行互相copy
- du
  - dfs -du [-s] [-h] URI [URI ...]
  - 显示目录下所有目录+文件大小；
  - 显示文件大小
  - -s是累加和
  - -h 是16进制？
- dus
- expunge 清空回收站
  - hadoop dfs -expunge
- get
  - 将文件拷贝到本地
  - hadoop dfs -get [-ignorecrc] [-crc] \<src> \<localdst>
  - CRC校验失败可以通过-ignorecrc 拷贝
- getmerge
  - hadoop dfs -getmerge \<src>\<localdst>  [addnl]
  - 将源文件目录下所有文件排序后合并到目的文件中
  - 添加addnl 可以在每个文件后面插入新行
- ls
  - 列出文件权限、副本个数、用户ID、组ID、文件大小、最近一次修改日期、时间、文件名
- lsr
- mkdir
- moveFromLocal
  - 源文件上传之后被删除
- moveToLocal
  - 下载后删除
- mv 删除
- put
  - 上传
- rm 删除参数指定的文件，只能删除文件和非空目录
  - hadoop dfs -rm [-skipTrash] URI [URI..]
  - skipTrash 不放到回收站直接删除
- rmr
- setrep 改变副本格式
- stat 路径状态
- tail
- test
  - hadoop dfs -test -[ezd] URI
  - -e 检查是否存在 存在返回0
  - -z 检查大小是否为0 是返回0
  - -d 检查路径是否为目录 是返回0
- text 将文本文件或某些格式的非文本文件输出
- touchz 创建一个大小为0的文件



### HDFS 基本接口

- 基本所有的文件API来自于FileSystem类

---

## CH4 MapReduce 并行编程框架

### 并行计算

划分子任务、计算、合并结果

![image-20220406145858596](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220406145858596.png)

### 构抽象模型Map与Reduce

#### Map

对一组数据元素进行某种重复式的处理

**map**: **(k1; v1)**$\rightarrow$ **[(k2; v2)]**

输入：键值对(k1; v1)表示的数据

处理：文档数据记录(如文本文件中的行，或数据表格中的行)将以“键值对”形式传入map函数；map函数将处理这些键值对，并以另一种键值对形式输出处理的一组键值对中间结果[(k2; v2)]

输出：键值对[(k2; v2)]表示的一组中间数据



#### Reduce

对Map的中间结果进行某种进一步的结果整理

例如关系数据库的聚合函数

**reduce**: **(k2; [v2])** $\rightarrow$  **[(k3; v3)]**

输入： 由map输出的一组键值对[(k2; v2)] 将被进行合并处理将同样主键下的不同数值合并到一个列表[v2]中，故reduce的输入为(k2; [v2]) 

处理：对传入的中间结果列表数据进行某种整理或进一步的处理,并产生最终的某种形式的结果输出[(k3; v3)] 。

输出：最终输出结果[(k3; v3)] 

---

![image-20220406150612183](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220406150612183.png)

Reduce前，必须所有map都做完，因此需要一个同步障barrier

这个阶段也负责对map中间结果数据进行收集整理和处理(aggregation、shuffle)

### 编程模型和框架

1. wordcount 伪代码

![image-20220406151147733](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220406151147733.png)

2. Combiner和Partitioner

   - Combiner

     在每个map节点输出中间结果的键值对前，进行合并处理，

     例如两个(good,1) 合并成(good,2)

     执行是在Map节点完成计算、输出中间结果之前

   - Partitioner

     分区处理

     目的：消除数据传入Reduce结点之后带来的不必要的相关性。

     在Map到Reduce中间数据整理阶段完成

     例如：保证所有主键相同的\<k,v>都输入到同一个Reduce节点，避免Reduce再访问其他Reduce

3. 完整的MapReduce并行编程框架

![image-20220406152908320](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220406152908320.png)

4. MapReduce提供了统一的计算框架可以完成
   - 计算任务的划分和调度
   - 数据分布存储和划分
   - 处理数据和计算任务同步
   - 结果数据的收集整理：sorting、combining、partitioning
   - 系统通信、负载平衡、计算性能优化处理
   - 节点出错检测、失效恢复
5. MapReduce提供的主要功能
   1. 任务调度：提交的一个计算作业(job)将被划分为很多个计算任务(tasks), 任务调度功能主要负责为这些划分后的计算任务分配和调度计算节点(map节点或reducer节点); 同时负责监控这些节点的执行状态, 并负责map节点执行的同步控制(barrier); 也负责进行一些计算性能优化处理, 如对最慢的计算任务采用多备份执行、选最快完成者作为结果
   2. 数据/代码互定位：为了减少数据通信，一个基本原则是本地化数据处理(locality)，即一个计算节点尽可能处理其本地磁盘上所分布存储的数据，这实现了代码向数据的迁移；当无法进行这种本地化数据处理时，再寻找其它可用节点并将数据从网络上传送给该节点(数据向代码迁移)，但将尽可能从数据所在的本地机架上寻找可用节点以减少通信延迟
   3. 出错处理：以低端商用服务器构成的大规模MapReduce计算集群中,节点硬件(主机、磁盘、内存等)出错和软件有bug是常态，因此,MapReducer需要能检测并隔离出错节点，并调度分配新的节点接管出错节点的计算任务
   4. 分布式数据存储与文件管理：海量数据处理需要一个良好的分布数据存储和文件管理系统支撑,该文件系统能够把海量数据分布存储在各个节点的本地磁盘上,但保持整个数据在逻辑上成为一个完整的数据文件；为了提供数据存储容错机制,该文件系统还要提供数据块的多备份存储管理能力
6. MapReduce的主要设计思想与特点
   - 向外扩展 而非向上纵向扩展
     - 即MapReduce集群的构筑选用价格便宜、易于扩展的大量低端商用服务器，而非价格昂贵、不易扩展的高端服务器（SMP）
   -  失效被认为是常态
     - 一个良好设计、具有容错性的并行计算系统不能因为节点失效而影响计算服务的质量，任何节点失效都不应当导致结果的不一致或不确定性；任何一个节点失效时，其它节点要能够无缝接管失效节点的计算任务；当失效节点恢复后应能自动无缝加入集群，而不需要管理员人工进行系统配置、
   - **把处理向数据迁移**
     - 计算节点将首先将尽量负责计算其本地存储的数据,以发挥数据本地化特点(locality),仅当节点无法处理本地数据时，再采用就近原则寻找其它可用计算节点，并把数据传送到该可用计算节点
   - **顺序处理数据、避免随机访问数据**
   -  **为应用开发者隐藏系统层细节**
   - **平滑无缝的可扩展性**

### 基本工作原理

#### 数据存储与计算节点

![image-20220427150638186](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427150638186.png)

#### 基本工作过程

![image-20220427150723707](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427150723707.png)

1. 在client node的client JVM里面提交MapReduce程序，然后run job on JobClient，Client需要复制Job资源到HDFS，然后get new job ID，之后才正式提交Job到JobTracker。
2. JobTracker 会初始化job，然后进行查询输入分片
3. TaskTracker 会 提交heartheat给JobTracker
4. TaskTracker 会 launch 一个child JVM 进行运行 MapTask 或者 ReduceTask

TaskTracker 与 Datanode 一对一，一般是看数据在哪一节点，就在哪个节点启动对应的TaskTracker。

![image-20220427153237278](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427153237278.png)

1. 指定输入格式，inputformat
2. 然后进行split
3. RecordReaders 读取每个记录转化成<k,v>
4. 输入到Map Task
5. 经过combiner、partition、同步障
6. 然后进行sort
7. reduce
8. 输出(k,v)
9. 最后写回HDFS

### 主要组件以及编程接口

#### 输入格式InputFormat

- InputFormat提供了以下一些功能
  - 选择文件或者其它对象，用来作为输入
  - 定义InputSplits, 将一个文件分为不同任务
  - 为RecordReader提供一个基础，用来读取这个文件
- 有一个抽象的类FileInputFormat，所有的输入格式类都从这个类继承其功能以及特性。当启动一个Hadoop任务的时候，一个输入文件所在的目录被输入到FileInputFormat对象中。FileInputFormat从这个目录中读取所有文件。然后FileInputFormat将这些文件分割为多个InputSplits
- 格式
  - TextInput Format
  - KeyValueTextInput Format
  - SequenceFileInput Format

- 一个MapReduce程序被统称为一个Job，可能有上百个任务构成

#### RecordReader

RecordReader实际上定义了如何将数据记录转化为一个(key,value)对的详细方法，并将数据记录传给Mapper类

#### Mapper

每一个Mapper类的实例生成了一个Java进程，负责处理某一个InputSplit上的数据。

#### Combiner

合并相同key的键值对，减少partitioning时候的数据通信开销。用户可以使用JobConf.setCombinerClass(class)自定制Combiner

#### Partition and Shuffle

  在Map完成之后，每一个Map函数的结果传到对应Reducer所在的节点，此时，可以提供一个Partition类，用来决定一个给定的(key,value)传给哪个Reduce节点

#### Sort

传到Reducer节点上的K,V会被Hadoop自动排序(即Map生成的结果传送到某个节点的时候会被自动排序)

#### Reducer

做用户定义的Reduce操作，OutputFormat输出

#### OutputFormat

继承自FileOutputFormat，每一个Reducer都写一个文件到一个共同的输出目录，名字是part-nnnn

```java
FileOutputFormat.setOutputPath();
JobConf.setOutputFormat();
```

### 容错处理

失败的任务再次执行

TaskTracker会把状态信息汇报给JobTracker，最终由JobTracker决定重新执行哪个任务

**投机执行**：为了加快执行速度，Hadoop会自动重复执行同一个任务，以最先执行成功的为准。

### 可解决的算法问题

**搜索引擎：文档倒排索引、网页链接图分析、页面排序**

Web日志分析、文档分析处理、机器学习、机器翻译等

#### MapReduce排序算法

[外排序与MapReduce的Sort](https://blog.csdn.net/qq_47865838/article/details/124000074?spm=1001.2014.3001.5501)

#### 构建单词同现矩阵算法

word co-occurrence matrix

- 是一个二维的N*N矩阵
- N是词汇量(不同单词的数目)
- 矩阵元素M(i,j) 标识单词Wi 和 Wj 在一定范围内同时出现的次数(可以定义窗口大小)

空间开销$O(n^2)$ ，内存和磁盘之间的换页会导致执行十分缓慢

M.R. 算法伪码

![image-20220427190133018](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427190133018.png)

- Mapper：文档d的每个单词，如果是同现窗口(word.neighbor)，对这个pair  count 一个 1
- shuffle & sort 把相同的pair 的count 变成一个count数组
- reduce: sum counts[i] -> s 

#### 专利文献数据分析

​	做的事是专利被引

​	最后输出: cited ; value: citing id1, citing id2…

## CH5 HBase

### HBase 基本工作原理

#### HBase设计目标和功能特点

- 针对HDFS缺少结构化半结构化数据存储访问能力的缺陷，提供一个分布式数据管理系统，解决大规模的结构化和半结构化数据存储访问问题
- HBase试图提供随机和实时的数据读写访问能力。具有高可扩展性、高可用性、容错处理能力、负载平衡能力、以及实时数据查询能力
- 是Google **Big Table**的开源实现
- **提供基于==列存储模式==的大数据表管理能力**

RDBMS 实现具有局限性：实现和操作都有局限性

RDBMS也有理论局限性：

- ACID，但是网络分片(Network Partitions)在分布式系统中不可避免系统扩展时性能和可靠性下降

使用NoSQL

- 每行的属性attribution可以不同，模式自由，但是尽量像表
- 能处理BigData

HBase是在HDFS基础上抽象出来的 **Column** **DB**，可与MapReduce协同工作，为MapReduce提供数据输入输出，以完成数据的并行化处理

#### Hbase 数据模型

**逻辑数据模型**：数据存储逻辑模型与BigTable类似,但实现上有一些不同之处是一个分布式多维表，表中的数据通过一个**行关键字(row key)一个列关键字(column family + column name)一个时间戳(time stamp)**进行索引和查询定位的

![image-20220427203059565](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427203059565.png)

**物理存储格式** 

按照==列存储==的稀疏矩阵，物理存储格式上按照逻辑模型种的行进行分隔，按照列族存储，值为空的列不存，节省空间

#### 基本架构

由一个MasterServer和由一组子表数据区服务器RegionServer构成，分别存储逻辑大表中的部分数据，大表中的底层数据存于HDFS中

也是主从结构 **Master Server + Region Server**

![image-20220427203512801](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427203512801.png)

**大表被分为很多个子表(Region) 每个子表存储在一个子表服务器Region Server上，Region 又分成store，store里面又有memSector和StoreFile，一个block size = 64MB，Region达到一定程度会分裂，每个列族对应一个store，写storeFile其实就是在写HDFSFile 是一个东西，并且HBase不用显式写副本，HDFS会自动对HFile 流水复制**

每个Store数据块又由存放在内存中的memStore和存放在文件中的StoreFile构成

当客户端需要进行数据更新时，先查到子表服务器,然后向子表提交数据更新请求。提交的数据并不直接存储到磁盘上的数据文件中，而是添加到一个基于内存的子表数据对象memStore中，当memStore中的数据达到一定大小时，系统将自动将数据写入到文件数据块StoreFile中，类似于**Lazy Write**,每个文件数据块StoreFile最后都写入到底层基于HDFS的文件中

需要查询数据时，子表先查memStore。如果没有，则再查磁盘上的StoreFile。每个StoreFile都有类似B树的结构，允许进行快速的数据查询。StoreFile将定时压缩，多个压缩为一个，两个小的子表可以进行合并，子表大到超过某个指定值时，子表服务器就需要调用HRegion.closeAndSplit(),把它分割为两个新的子表。



![image-20220427205311595](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220427205311595.png)



**HBase主服务器**

与BigTable类似，HBase使用主服务器HServer来管理所有子表服务器。主服务器维护所有子表服务器在任何时刻的状态

当一个新的子表服务器注册时，主服务器让新的子表服务器装载子表

若主服务器与子表服务器连接超时，那么**子表服务器将自动停止**，并重新启动；而主服务器则假定该子表服务器已死机，**将其上的数据转移至其它子表服务器**，将其上的子表标注为空闲，并在重新启动后**另行分配**使用

**关于元数据：**

描述所有子表和子表中数据块的元数据都存放在专门的元数据表中,并存储在特殊的子表中。子表元数据会不断增长，因此会使用多个子表来保存。

所有元数据子表的元数据都保存在根子表中。主服务器会扫描根子表，从而得到所有的元数据子表位置，再进一步扫描这些元数据子表即可获得所寻找子表的位置

**HBase 使用三层类似于B+树的结构保存Region位置(索引？)**

简言之：三层索引结构: ==**根子表->用户表的元数据表->用户表**==

- 第一层，保存zookeeper里面文件，它保存root region位置
- 爹日次，root region是META表第一个Region，里面保存了META表和其他region位置，访问Root Region从而访问META表数据
- META是第三层，是一个特殊表，保存了HBASE所有表的Region位置信息

### HBase 基本操作与编程方法

#### Shell 操作

Create、Describe、Disable、enable、drop、list、scan、put、get、delete、count、status等

```bash
create 'student','ID','Description','Course','Home'
```

第一个是表明，然后后面 注意 **每一行的列可以不一样，换言之：列是实例，列簇是模式，列簇要一样**

插入数据

```bash
put 'students','001','Description:Name','LL'
put 'students','001','Description:Height','LL'
put 'students','001','Course:Chinese','LL'
```

**Disable和enable**

1. 很多对table的修改都需要表在disable的状态下才能进行
2. disable ‘students′将表students的状态更改为disable的时候，HBase会在zookeeper中的table结点下做记录
3. 在zookeeper记录下修改该表的同时，还会将表的region全部下线，region为**offline**状态
4. enable的过程和disable相反，会把表的所有region上线，并删除zookeeper下的标志。如果在enable前，META中有region的server信息，那么此时会在该server上将该region 上线；如果没有server的信息，那么此时还要随机选择一台机器作为该region的server

so Region and Server maybe is Separated?

#### HBase Java编程

1. HBaseConfiguration是每一个hbase client都会使用到的对象，它代表的是HBase配置信息

2. 默认的构造方式会尝试从hbase-default.xml和hbase-site.xml中读取配置

3. **创建表**：通过HBaseAdmin，提供了createTable

4. 插入数据：HTable通过put方法来插入数据

5. **删除表**也通过HBaseAdmin来操作，删除表之前首先要**disable**表。这是一个非常耗时的操作，所以**不建议频繁删除表**。disableTable和deleteTable分别用来disable和delete表

6. **查询**：单条查询是通过rowkey在table中查询某一行的数据。HTable提供了get方法来完成单条查询。

   批量查询是通过制定一段rowkey的范围来查询。HTable提供了个getScanner方法来完成批量查询

7. 切分表：参数hbase.hregion.max.filesize指示在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region

   还可以手工split，如果提供tableName，那么会将table所有region进行split ;如果提供region Name，那么只会split这个region

8. 当然HBase 支持MapReduce编程



### HBase 实验

[Big-Data-Analysis/Lab1](https://github.com/Tcoder-l3est/Big-Data-Analysis/tree/main/Lab1)

## CH6 Hive





---

## CH7 Spark

>  Why spark?
>
> Hadoop 计算框架对很多非批处理大数据问题的局限性，除了基于Hadoop、Hbase的数据存储管理模式和MapReduce模式之外，后Hadoop时代新的计算模式和系统出现，**尤其是以内存计算为核心，集诸多计算模式的Spark产生~**

### Spark 基于内存计算思想提高计算性能

RDD : Relisent Distribute Dataset 弹性分布式数据集

Spark 

RDD 只读，不能修改，不然产生新的RDD

计算过程一组RDD构成可执行的DAG，灵活的计算流图

**Speed Fast**

### Spark 基本构件和组件



#### Spark 集群的基本结构



#### Spark 应用程序的基本结构

DAG，操作之间有没有依赖，来决定并行或者串行





### Spark 程序执行过程



### Spark 技术特点



### Spark 编程模型



```scala
def main(){
    
}
```











