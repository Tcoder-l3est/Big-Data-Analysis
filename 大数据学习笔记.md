# BIG DATA课程笔记

## 导论

大数据的四大特征

​	**大量化、快速化、多样化、价值化**

大数据分析的三个特征

​	**全样而非抽样、效率而非精确、相关而非因果**

大数据处理模型：

​	批处理：以“静止数据”为出发点，处理逻辑进来，算完后价值出去

​	流数据：不动的是逻辑，“动态数据”进来，计算完后价值留下，原始数据加入“静止数		据”，或索性丢弃

其中批处理包括MapReduce模型

大数据技术和工具

- NoSQL，not only sql，模式自由、简易备份、简单API、不支持ACID但是支持BASE、支持海量数据
  - 做了查询优化
    - 利用MapReduce时并行查询、每个MapTask处理一部分
  - 采用索引技术优化多指查询，多维索引
- 流处理模式：Storm
- 工具：Hadoop、Spark

---

## Hadoop 简介

### 概念

1. MapReduce采用了分布式文件系统即HDFS，也就是Hadoop 分布式文件系统，MapReduce是用来整合DFS的数据的

2. 存储冗余数据保证安全性

3. 对比关系型数据库RDBMS，RDBMS适合查询更新、MapReduce适合批处理。RDBMS 适合持续更新的数据集，MapReduce适合一次写入多次读取。RDBNMS只能处理结构化数据，MapReduce能够处理半结构化或者非结构化。

   ![image-20220405200729138](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405200729138.png)

### 体系结构



![image-20220405201056878](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405201056878.png)

- 最底部是Hadoop分布式文件系统（HDFS），它存储Hadoop集群中所有存储节点上的文件

- HDFS的上一层是MapReduce引擎
- HBase位于结构化存储层，是一个分布式的列存储数据库
- Zookeeper是一个分布式的、高可用性的协调服务，提供分布式锁之类的基本服务
- Hive是一个建立在Hadoop 基础之上的数据仓库，用于管理存储于HDFS或Hbase中的结构化/半结构化数据
- Pig提供一种数据流语言，程序员可以将复杂的数据分析任务实现为Pig操作上的数据流脚本，这些脚本可自动转换为MapReduce任务链，在Hadoop上执行，从而简化程序员的数据分析工作难度
- Sqoop是SQL-to-Hadoop的缩写，为在RDBMS与Hadoop平台（HDFS, Hbase, Hive）间进行快速批量数据交换
- Avro是个数据序列化的系统，用于将数据对象转换成便于数据存储和网络传输的格式
- 一个HDFS集群是由一个NameNode和若干个DataNode组成
- NameNode作为主服务器，**管理文件系统的命名空间和客户端对文件的访问操作**；集群中的**DataNode管理存储的数据**
- HDFS支持用户以文件的形式存储数据，文件被分成若干个数据块，而且这若干个数据块存放在一组DataNode上
- 具体到程序层面：MapReduce框架是由一个单独运行在主节点上的JobTracker 和运行在每个集群从节点上的TaskTracker共同组成的
  - 主节点负责调度构成一个作业的所有任务，这些任务分布在不同的从节点上；主节点监控它们的执行情况，并且重新执行之前失败的任务。从节点仅负责由主节点指派的任务
  - 当一个Job 被提交时，JobTracker接收到提交作业和配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行
- TaskTracker和DataNode需配对的设置在同一个物理的从节点服务器上；JobTracker和NameNode可以设置在同一个物理主控节点服务器上，也可以分开设置

### Hadoop与分布式开发

![image-20220405202959992](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405202959992.png)

![image-20220405204705230](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405204705230.png)

**编程原理**

- 利用一个输入的key/value 对集合,来产生一个输出的key/value 对集合。这个过程基于Map 和Reduce这两个用户自定义函数实现
- 用户自定义的map函数接收一个输入的key/value 对，然后产生一个中间key/value 对的集合
- MapReduce（shuffle）把所有具有相同key值的value集合在一起，然后传递给reduce 函数
- 用户自定义的reduce 函数接收key和相关的value集合，合并这些value 值，形成一个较小的value 集合。一般来说，每次reduce 函数调用只产生0 或1 个输出的value值
- 通常通过一个迭代器把中间的value 值提供给reduce 函数，这样就可以处理无法全部放入内存中的大量的value 值集合

**基于Map和Reduce的并行计算模型**

![image-20220405203254179](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405203254179.png)

其中

- Barrier是同步障

---

## 存储——HDFS

### 概念

- HDFS的块是抽象的概念，默认块为64MB，比一般文件系统中所说的块（若干KB）要大得多
  - 好处：文件大、便于操作、复制容错
- 两类节点：NameNode和DataNode
  - NameNode：集群里面的主节点，负责管理整个HDFS系统的命名空间和元数据，也是客户端访问HDFS系统的入口
  - 三种**元数据metadata如下**
    - 命名空间：即目录结构、命名空间维护操作包括文件和目录的创建删除重命名
    - 数据块和文件名的映射表：客户点需要访问NameNode才知道一个文件所有的数据块保存在那些DataNode上
    - 数据块副本的位置信息，默认三个副本，可以指定部分银子Replication Factor
    - 承担Master任务
  - DataNode：负责数据读取和存储
    - 写入时：目录节点分配数据块，直接写入对应的DataNode
    - 读取：客户点从NameNode获得映射关系后，直接到DataNode读
    - DataNode根据NameNode的命令创建、删除数据块，副本复制

### HDFS 体系结构

![image-20220405205441702](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405205441702.png)

- HDFS是经典的主从结构
- HDFS的基本文件的访问过程
  - 通过HDFS客户端，奖文件名发送到NameNode
  - 接收后，在HDFS目录中检索文件名对应的数据库，找到对应的DataNode，然后送回客户端
  - 接收后，与DataNode并行进行数据传输，提交操作日志到NameNode
- HDFS不允许使用链接
- 为了保证可靠性，底层使用TCP来传输。
  - 应用向NameNode主动发出TCP链接，交互的协议成为Client协议
  - NameNode与DataNode传输的协议成为DataNode协议
  - 用户与Datanode的协议是通过远程过程调用RPC、并由NameNode相应来实现
  - 如下图

![image-20220405213033545](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213033545.png)

![image-20220405210648449](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405210648449.png)

这个图可以看出什么信息呢？

- Client会从Datanodes读
- Client写的时候 会写副本吗？
- Rack是机柜，Replication是复制、
- Namenode会对Datanodes进行快操作

### HDFS可靠性设计

- 除了文件的最后一块以外其它所有的数据块都是固定大小的，为了数据容错性，每一个数据块都会被冗余存储起来

- 目录节点根据数据块的副本状况来作出处理决策，数据节点会定期发送一个**心跳信号（Heartbeat）**和数据块列表给目录节点，心跳信号使目录节点知道该数据节点还是有效的，而数据块列表包括了该数据节点上面的所有数据块编号

- 数据节点出错的处理

  - 每个数据节点会定时发送一个心跳信息给目录节点，表明自己仍然存活

  - 网络异常可能会导致一部分数据节点无法和目录节点通讯，这时候目录节点收不到心跳信息，就认为该数据节点已死机

    然后：从有效数据节点列表中清除它，而该数据节点上面的所有数据块也会被标记为不可读。目录节点会定期检查副本数，进行复制。

- 数据异常

  - 客户端需实现对数据块的校验，保证数据一致性
  - 在创建文件的时候，HDFS会为文件生成一个校验和（CheckSum），校验和文件与文件本身保存在同一个空间中。数据传输时，将数据与校验和一起传输，客户端对每个读取的数据块进行校验
  - 如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且报告给目录节点这个文件块有错误，目录节点会重新复制这个块

- 目录节点出错

  - HDFS刚启动时，目录节点进入安全模式（safe mode），**此时不做任何文件修改操作**；目录节点和各个数据节点通信，获得数据块信息，并对数据块信息进行检查；认为安全的块比例超过阈值，才退出安全模式

  - 辅助目录节点，用来备份目录节点的元数据，当目录节点失效时，从辅助目录节点恢复出目录节点的元数据

  - 文件镜像数据**FsImage**和编辑日志数据**Editlog**是目录节点元数据中最重要的部分，前者相当于HDFS的**检查点**，后者记录对HDFS的**最新修改信息**

  - 恢复：目录节点启动时，读取FsImage的内容到内存，并将其与Editlog中的所有修改信息合并生成最新的FsImage；目录节点运行中，所有关于HDFS的修改信息，都将写入Editlog

    - FsImage和Editlog时最核心的数据结构
    - 所以存在多个备份文件，在辅助目录节点上再进行备份，增加负担提高可靠性。维护同步

    

### HDFS存储原理

- 以机柜为基础
- 副本因子为3：HDFS将两份放在同一个rack id中，另一个放在不同的rankid的机器上
- 实战中Namenode
  - ![image-20220405213805409](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213805409.png)
  - ![image-20220405213854377](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213854377.png)
  - ![image-20220405213941210](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405213941210.png)
- DataNode
  - ![image-20220405214008805](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214008805.png)
  - ![image-20220405214230211](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214230211.png)
  - 

- **数据读取时**
  - 如果有块数据和客户端的机柜id一样，就优先选择该数据节点，客户端直接和数据节点建立连接，读取数据
  - 如果没有，可以随机选取一个数据节点

![image-20220405212824697](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405212824697.png)

![image-20220405212932527](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405212932527.png)

- **数据复制**
  - **流水线复制策略**
  - 当在HDFS上写文件：
    - 先写在本地
    - 对文件分块，64MB
    - 每块数据对HDFS目录节点发起写入请求
    - NameNode选一个DataNode列表，返回给客户端
    - 客户端把数据写入第一台DataNode，列表传给DataNode
    - 当数据节点接收到4KB数据时，写入本地，并且发起到下一台Datanode的连接，传4K，流水线
    - 当文件写完时，数据复制也同时完成？
- **数据写入**
  - ![image-20220405214436163](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214436163.png)
  - ![image-20220405214544884](https://vvtorres.oss-cn-beijing.aliyuncs.com/image-20220405214544884.png)

---

### HDFS文件系统操作命令



